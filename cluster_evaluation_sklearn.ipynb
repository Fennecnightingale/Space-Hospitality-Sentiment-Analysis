{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('final.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>earth order survive must stop global warming ...</td>\n",
       "      <td>14116.0</td>\n",
       "      <td>UCmERzF_P0BZWGGjr2wGGnMQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UgjwmZLS1tubQHgCoAEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>phase 4 moon declares independence tired eart...</td>\n",
       "      <td>12898.0</td>\n",
       "      <td>UCRgqsjV2VMb11prjm_bIC8Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UgxivzlZzuWNuRWrzCd4AaABAg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>let get straight guy astronaut great public s...</td>\n",
       "      <td>10670.0</td>\n",
       "      <td>UCwrM8uIAgp_QiA2VgdJeJRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UgzXTACB0RAyXP1bs-Z4AaABAg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>walk spider web australia thats called assist...</td>\n",
       "      <td>9282.0</td>\n",
       "      <td>UC_m10vuJcLOosqYT5oOAKvg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ughn5RK44AmdrngCoAEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>love video send existentialist crisis others ...</td>\n",
       "      <td>6820.0</td>\n",
       "      <td>UCcnv-fzEfAhmRyWC60HFSSg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ugy3G3MZ7gCjCOxRSlF4AaABAg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             3   \n",
       "3           3             5   \n",
       "4           4             6   \n",
       "\n",
       "                                                text  favorite_count  \\\n",
       "0   earth order survive must stop global warming ...         14116.0   \n",
       "1   phase 4 moon declares independence tired eart...         12898.0   \n",
       "2   let get straight guy astronaut great public s...         10670.0   \n",
       "3   walk spider web australia thats called assist...          9282.0   \n",
       "4   love video send existentialist crisis others ...          6820.0   \n",
       "\n",
       "                    user_id mentions  repost_count                     post_id  \n",
       "0  UCmERzF_P0BZWGGjr2wGGnMQ      NaN           0.0        UgjwmZLS1tubQHgCoAEC  \n",
       "1  UCRgqsjV2VMb11prjm_bIC8Q      NaN           0.0  UgxivzlZzuWNuRWrzCd4AaABAg  \n",
       "2  UCwrM8uIAgp_QiA2VgdJeJRA      NaN           0.0  UgzXTACB0RAyXP1bs-Z4AaABAg  \n",
       "3  UC_m10vuJcLOosqYT5oOAKvg      NaN           0.0        Ughn5RK44AmdrngCoAEC  \n",
       "4  UCcnv-fzEfAhmRyWC60HFSSg      NaN           0.0  Ugy3G3MZ7gCjCOxRSlF4AaABAg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = ['final_clean_4_word.csv', 'final_clean_5_word.csv', 'final_clean_6_word.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[['favorite_count']] = scaler.fit_transform(df[['favorite_count']])\n",
    "df[['repost_count']] = scaler.fit_transform(df[['repost_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'user_id', 'mentions', 'post_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>repost_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earth order survive must stop global warming ...</td>\n",
       "      <td>0.248788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phase 4 moon declares independence tired eart...</td>\n",
       "      <td>0.227322</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>let get straight guy astronaut great public s...</td>\n",
       "      <td>0.188054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walk spider web australia thats called assist...</td>\n",
       "      <td>0.163591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love video send existentialist crisis others ...</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  favorite_count  \\\n",
       "0   earth order survive must stop global warming ...        0.248788   \n",
       "1   phase 4 moon declares independence tired eart...        0.227322   \n",
       "2   let get straight guy astronaut great public s...        0.188054   \n",
       "3   walk spider web australia thats called assist...        0.163591   \n",
       "4   love video send existentialist crisis others ...        0.120200   \n",
       "\n",
       "   repost_count  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer_and_hstacker(dataframe):\n",
    "    # create the TDIDF transform\n",
    "    vect = TfidfVectorizer().fit_transform(dataframe['text']) \n",
    "    print('tfidf vectorizing complete')\n",
    "    # determine components, here I'm reducing dimensionality by a factor of 100, and making sure our minimum is at least 100\n",
    "    components = max(vect.shape[0]//100, 100)\n",
    "    # doing some PCA to reduce our dimensions to make this faster and easier to work with \n",
    "    svd = TruncatedSVD(n_components=components, n_iter=5, random_state=0)\n",
    "    print('dimensionality reduction complete')\n",
    "    # transforming our text matrix and transforming it back to a matrix after transforming \n",
    "    vect = csr_matrix(svd.fit_transform(vect)) \n",
    "    #turning our other x variables into a matrix so we can combine all our features into one \n",
    "    x_mtx = MinMaxScaler().fit_transform(csr_matrix(dataframe[['favorite_count', 'repost_count']])) \n",
    "    # stacking our matricies into a single matrix to model off of \n",
    "    haystack = hstack([x_mtx, vect])\n",
    "    print('matrix complete')\n",
    "    return haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf vectorizing complete\n",
      "dimensionality reduction complete\n"
     ]
    }
   ],
   "source": [
    "vectorizer_and_hstacker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "ScoreList   = []\n",
    "maxNumberOfClusters=20\n",
    "\n",
    "for i in range(3, maxNumberOfClusters):\n",
    "    km = KMeans(n_clusters=i, \n",
    "                init='k-means++', \n",
    "                n_init=10, \n",
    "                max_iter=300, \n",
    "                random_state=0)\n",
    "    km.fit_predict(haystack)\n",
    "    distortions.append(km.inertia_)\n",
    "    ScoreList.append(-km.score(haystack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(dataframe):\n",
    "    fav_std = dataframe['favorite_count'].std()\n",
    "    fav_mean = dataframe['favorite_count'].mean()\n",
    "    repo_std = dataframe['repost_count'].std()\n",
    "    repo_mean = dataframe['repost_count'].mean()\n",
    "    \n",
    "    for i in range(len(dataframe)):\n",
    "        dataframe.at[i, 'favorite_count'] = (dataframe.at[i, 'favorite_count'] - fav_mean)/fav_std\n",
    "        dataframe.at[i, 'repost_count'] = (dataframe.at[i, 'repost_count']- repo_mean)/repo_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterizer(dataframe, haystack, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters,\n",
    "                    init='k-means++',\n",
    "                    n_init=10,\n",
    "                    max_iter=300,\n",
    "                    tol=1e-04,\n",
    "                    random_state=0)\n",
    "    \n",
    "    fit_predict = kmeans.fit_predict(haystack)\n",
    "    dataframe['cluster'] = fit_predict\n",
    "    return kmeans, fit_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayer(dataframe):\n",
    "    cluster_array = dataframe['cluster'].to_frame().to_numpy()\n",
    "    return cluster_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_silhouette(haystack, cluster, array, csv):\n",
    "    cluster_labels = np.unique(fit_predict)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_samples(haystack, fit_predict, metric='euclidean')\n",
    "    y_ax_lower, y_ax_upper = 0, 0\n",
    "    yticks = []\n",
    "    for i, c in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[fit_predict == c]\n",
    "        c_silhouette_vals.sort()\n",
    "        y_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0, \n",
    "                 edgecolor='none', color=color)\n",
    "        yticks.append((y_ax_lower + y_ax_upper) / 2.)\n",
    "        y_ax_lower += len(c_silhouette_vals)\n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n",
    "    plt.yticks(yticks, cluster_labels + 1)\n",
    "    plt.ylabel('Cluster')\n",
    "    plt.xlabel('Silhouette coefficient')\n",
    "    print(csv[12:19].replace('_', ' ') + ' ' + str(n_clusters) + ' ' + str(round(cluster.inertia_, 2)))\n",
    "    plt.savefig(str(round(cluster.inertia_/1000, 0)) + 'k_' + csv[12:] + '_' + str(n_clusters) + '_clst.png', dpi=300)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in csvs:\n",
    "    dataframe = pd.read_csv(csv, low_memory=False)\n",
    "    normalizer(dataframe)\n",
    "    stack = vectorizer_and_hstacker(dataframe)\n",
    "    for i in range(3,12,2):\n",
    "        cluster, fit_predict = clusterizer(dataframe, stack, i)\n",
    "        cluster_array = arrayer(dataframe)\n",
    "        make_silhouette(stack, cluster, cluster_array, csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
