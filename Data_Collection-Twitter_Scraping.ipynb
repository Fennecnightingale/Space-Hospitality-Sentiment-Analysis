{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conscious-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import twython\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "social-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forty-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "from contextlib import suppress\n",
    "from requests_oauthlib import OAuth1Session\n",
    "from apscheduler.schedulers.background import BackgroundScheduler as Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "funky-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your keys/secrets as strings in the following fields\n",
    "credentials = {}\n",
    "credentials['CONSUMER_KEY'] = '3mnbKAJQ1mTqqCUkflnMPU7Yd'\n",
    "credentials['CONSUMER_SECRET'] = 'u1S9w46A0bswd3famLV0AE20MJng022uEu2P6s4RpQ5NwVlblY'\n",
    "credentials['ACCESS_KEY'] = '1308202324725121025-Bea5jYYdFz150u4Unj9n1yvoK4f66p' \n",
    "credentials['ACCESS_SECRET'] = 'DzCPzqqyOlcjKxgduKcw6OEIqsucz1jIrl1Zh8PxvUsEm'\n",
    "\n",
    "# Save the credentials object to file\n",
    "with open(\"data/twitter_credentials.json\", \"w\") as file:\n",
    "    json.dump(credentials, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "executed-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials from json file\n",
    "with open(\"data/twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "worth-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the header for our dataframe so we have something to append to \n",
    "startdf = pd.read_csv('df')\n",
    "# when our dataframe is created the index is unnamed, when you export it is renamed so we need to fix it so our df realizes it's the same \n",
    "startdf = startdf.head(0).rename(columns={'Unnamed: 0':''})\n",
    "#assign our id as the most recent tweet id to start so that we get everything after it \n",
    "id_ = python_tweets.search(**{'q': 'RT', 'result_type': 'recent', 'count': 2})['statuses'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "alleged-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfn(q, name):\n",
    "    # import global variables we will be using this function to alter\n",
    "    global id_\n",
    "    global startdf \n",
    "    # Create our query\n",
    "    query = {'q': q,\n",
    "            'result_type': 'recent',\n",
    "            'count': 100,\n",
    "            'lang': 'en',\n",
    "            'max_id': id_,\n",
    "            'tweet_mode' : 'extend',\n",
    "            'entities': {\n",
    "                \"hashtags\": [],\n",
    "                \"symbols\": [],\n",
    "                \"user_mentions\": []\n",
    "            }\n",
    "            }\n",
    "    #build our query into a dictionary to easily turn into dataframe \n",
    "    dict_ = {'user': [], 'user_id':[], 'post_id': [], 'text': [], 'favorite_count': [], 'hashtags':[], 'symbols':[], 'user_mentions':[], \n",
    "             'retweet_count':[]}\n",
    "    for status in python_tweets.search(**query)['statuses']:\n",
    "        dict_['user'].append(status['user']['screen_name'])\n",
    "        dict_['user_id'].append(status['user']['id'])\n",
    "        dict_['text'].append(status['text'])\n",
    "        dict_['hashtags'].append(status['entities']['hashtags'])\n",
    "        dict_['symbols'].append(status['entities']['symbols'])\n",
    "        dict_['user_mentions'].append(status['entities']['user_mentions'])\n",
    "        dict_['favorite_count'].append(status['favorite_count'])\n",
    "        dict_['retweet_count'].append(status['retweet_count'])\n",
    "        dict_['post_id'].append(status['id'])\n",
    "    # put data in a DataFrame to work with it easier\n",
    "    df = pd.DataFrame(dict_)\n",
    "    #removing our vairables stuck in dictionaries within our dataframe and give them their own columns\n",
    "    df['mentions'] = ' '\n",
    "    df['hashtag'] = ' '\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df.at[i, 'user_mentions'])):\n",
    "            try:\n",
    "                df.at[i, 'mentions'] = str(df.at[i, 'mentions']) + ' ' + str(df.at[i, 'user_mentions'][j]['id'])\n",
    "            except:\n",
    "                df.at[i, 'mentions'] = str(df.at[i, 'mentions'])\n",
    "        for k in range(len(df.at[i, 'hashtags'])):\n",
    "            try:\n",
    "                df.at[i, 'hashtag'] = str(df.at[i, 'hashtag']) + ' ' + str(df.at[i, 'hashtags'][k]['text'])\n",
    "            except:\n",
    "                df.at[i, 'hashtag'] = str(df.at[i, 'hashtag'])\n",
    "    # get rid of columns that we took everything we need from \n",
    "    df = df.drop(['user_mentions', 'hashtags'], 1)\n",
    "    startdf = startdf.append(df)\n",
    "    # not sure why id_ doesn't want to change unless reset but do it because it works and can't hurt\n",
    "    id_ = None\n",
    "    # get oldest id_ (lowest number) and subtract one so that that you don't reinclude it in the next search\n",
    "    # reset id_ to be oldest\n",
    "    try: \n",
    "        id_ = int(df['post_id'].sort_values(ascending=True).to_frame().reset_index()['post_id'][0]) - 1 \n",
    "    except:\n",
    "        id_ = python_tweets.search(**{'q': 'RT', 'result_type': 'recent', 'count': 2})['statuses'][0]['id']\n",
    "    return startdf, id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "interstate-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'astronomy', 'Starship', 'mars', 'curiosityrover', 'oppertunityrover', 'starlink', 'falconheavy', 'sls','ESA', 'NASA', 'spacex', 'virgingalactic', 'virginorbit', 'JAXA', 'Roscosmos', 'artemis', \n",
    "# 'starliner', 'blueorigin', 'spacetravel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "twenty-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = ['marswebcam', 'falcon9', 'nasa_app', 'universe', 'cosmos', 'iss', 'climate', 'internationalspacestation', 'futurism', 'starliner', 'blueorigin', 'spacetravel', 'astronomy', 'mars', 'curiosityrover', 'oppertunityrover', 'starlink', 'falconheavy', 'sls','ESA', 'NASA', 'spacex', 'virgingalactic', 'virginorbit', 'JAXA', 'Roscosmos', 'areospace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "yellow-closer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting marswebcam time : 22:21:02, ending time: 22:46:01\n",
      "starting falcon9 time : 22:46:02, ending time: 23:11:01\n",
      "starting nasa_app time : 23:11:02, ending time: 23:36:01\n",
      "starting universe time : 23:36:02, ending time: 00:01:01\n",
      "starting cosmos time : 00:01:02, ending time: 00:26:01\n",
      "starting iss time : 00:26:02, ending time: 00:51:01\n",
      "starting climate time : 00:51:02, ending time: 01:16:01\n",
      "starting internationalspacestation time : 01:16:02, ending time: 01:41:01\n",
      "starting futurism time : 01:41:02, ending time: 02:06:01\n",
      "starting starliner time : 02:06:02, ending time: 02:31:01\n",
      "starting blueorigin time : 02:31:02, ending time: 02:56:01\n",
      "starting spacetravel time : 02:56:02, ending time: 03:21:01\n",
      "starting astronomy time : 03:21:02, ending time: 03:46:01\n",
      "starting mars time : 03:46:02, ending time: 04:11:01\n",
      "starting curiosityrover time : 04:11:02, ending time: 04:36:01\n",
      "starting oppertunityrover time : 04:36:02, ending time: 05:01:01\n",
      "starting starlink time : 05:01:02, ending time: 05:26:01\n",
      "starting falconheavy time : 05:26:02, ending time: 05:51:01\n",
      "starting sls time : 05:51:02, ending time: 06:16:01\n",
      "starting ESA time : 06:16:02, ending time: 06:41:01\n",
      "starting NASA time : 06:41:02, ending time: 07:06:01\n",
      "starting spacex time : 07:06:02, ending time: 07:31:01\n",
      "starting virgingalactic time : 07:31:02, ending time: 07:56:01\n",
      "starting virginorbit time : 07:56:02, ending time: 08:21:01\n",
      "starting JAXA time : 08:21:02, ending time: 08:46:01\n",
      "starting Roscosmos time : 08:46:02, ending time: 09:11:01\n",
      "starting areospace time : 09:11:02, ending time: 09:36:01\n"
     ]
    }
   ],
   "source": [
    "# eventual goal is to use those loop to do all of our searches\n",
    "end_item = datetime.datetime.now()\n",
    "id_ = python_tweets.search(**{'q': 'RT', 'result_type': 'recent', 'count': 2})['statuses'][0]['id']\n",
    "\n",
    "for item in query_list:\n",
    "    #reset id_ to be most recent tweet for each item\n",
    "    id_ = python_tweets.search(**{'q': 'RT', 'result_type': 'recent', 'count': 2})['statuses'][0]['id']\n",
    "    # for each item, reset the start time to the end of the last item \n",
    "    start_time = end_item + datetime.timedelta(seconds=1)\n",
    "    # set the end time to be 90 min after you start, gathering 50 tweets every 100 seconds for 2,700 tweets from each item in list\n",
    "    end_item = end_item + datetime.timedelta(seconds=1500)\n",
    "    #print start and end times so I know when the program will be finished and where it should be at \n",
    "    print(f'starting {item} time : {start_time.strftime(\"%H:%M:%S\")}, ending time: {end_item.strftime(\"%H:%M:%S\")}')\n",
    "    #occassionally getting key/value errors of 0 that I cannot find the cause of, but do not affect anything in how our dataframe\n",
    "    #is made, I just don't want them printing \n",
    "    with suppress(KeyError, ValueError):\n",
    "        #initiate scheduler\n",
    "        sch = Scheduler()\n",
    "        #add our function and items, we're doing 50/10 seconds \n",
    "        sch.add_job(myfn, 'interval', (item, startdf), seconds= 5, start_date=start_time, end_date=end_item)\n",
    "        #start scheduler\n",
    "        sch.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "infrared-colon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649309"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(startdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "double-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>post_id</th>\n",
       "      <th>symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rnitsch</td>\n",
       "      <td>55369958</td>\n",
       "      <td>RT @esamarswebcam: New VMC Images direct from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>158283753</td>\n",
       "      <td>marswebcam</td>\n",
       "      <td>1379577401626263560</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AK9dj</td>\n",
       "      <td>1303105529892364289</td>\n",
       "      <td>RT @esamarswebcam: New VMC Images direct from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158283753</td>\n",
       "      <td>marswebcam</td>\n",
       "      <td>1379575449290895360</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>esamarswebcam</td>\n",
       "      <td>158283753</td>\n",
       "      <td>New VMC Images direct from Mars! 22 images tak...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>marswebcam</td>\n",
       "      <td>1379572699794640902</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nasafan_</td>\n",
       "      <td>1274008106083770368</td>\n",
       "      <td>RT @esamarswebcam: New VMC Images direct from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158283753</td>\n",
       "      <td>marswebcam</td>\n",
       "      <td>1379572287725264898</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>esamarswebcam</td>\n",
       "      <td>158283753</td>\n",
       "      <td>New VMC Images direct from Mars! 74 images tak...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>marswebcam</td>\n",
       "      <td>1379572106430709760</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RichTPar</td>\n",
       "      <td>199730805</td>\n",
       "      <td>RT @ISAS_JAXA_EN: From this week, the Hayabusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1354997580346716164</td>\n",
       "      <td></td>\n",
       "      <td>1377462589634977793</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Grace68738590</td>\n",
       "      <td>1219765988452782080</td>\n",
       "      <td>@Thom_astro @SpaceX @NASA_Astronauts @esa @JAX...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>437520768 34743251 43166813 21436960 104989762</td>\n",
       "      <td></td>\n",
       "      <td>1377462519929872394</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>XKblo</td>\n",
       "      <td>67767462</td>\n",
       "      <td>RT @jaxa_wdc: Navigating satellites away from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>4529166736</td>\n",
       "      <td></td>\n",
       "      <td>1377462058334228483</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tokolose</td>\n",
       "      <td>950701406</td>\n",
       "      <td>@ArduinoMakes @antonioastro_ @TJ_Cooney Sure a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>945002912023023616 1214972829449539584 11339...</td>\n",
       "      <td></td>\n",
       "      <td>1377460988006531074</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>kuru_kittokuru</td>\n",
       "      <td>2383697352</td>\n",
       "      <td>@Thom_astro @Aki_Hoshide @NASA_NEEMO @JAXA_en ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>437520768 390455433 135275592 104989762</td>\n",
       "      <td></td>\n",
       "      <td>1377458972597186565</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593275 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user              user_id  \\\n",
       "0   NaN         rnitsch             55369958   \n",
       "1   NaN           AK9dj  1303105529892364289   \n",
       "2   NaN   esamarswebcam            158283753   \n",
       "3   NaN        nasafan_  1274008106083770368   \n",
       "4   NaN   esamarswebcam            158283753   \n",
       "..  ...             ...                  ...   \n",
       "95  NaN        RichTPar            199730805   \n",
       "96  NaN   Grace68738590  1219765988452782080   \n",
       "97  NaN           XKblo             67767462   \n",
       "98  NaN        Tokolose            950701406   \n",
       "99  NaN  kuru_kittokuru           2383697352   \n",
       "\n",
       "                                                 text favorite_count  \\\n",
       "0   RT @esamarswebcam: New VMC Images direct from ...              0   \n",
       "1   RT @esamarswebcam: New VMC Images direct from ...              0   \n",
       "2   New VMC Images direct from Mars! 22 images tak...              4   \n",
       "3   RT @esamarswebcam: New VMC Images direct from ...              0   \n",
       "4   New VMC Images direct from Mars! 74 images tak...              3   \n",
       "..                                                ...            ...   \n",
       "95  RT @ISAS_JAXA_EN: From this week, the Hayabusa...              0   \n",
       "96  @Thom_astro @SpaceX @NASA_Astronauts @esa @JAX...              0   \n",
       "97  RT @jaxa_wdc: Navigating satellites away from ...              0   \n",
       "98  @ArduinoMakes @antonioastro_ @TJ_Cooney Sure a...              0   \n",
       "99  @Thom_astro @Aki_Hoshide @NASA_NEEMO @JAXA_en ...              0   \n",
       "\n",
       "   retweet_count                                           mentions  \\\n",
       "0              3                                          158283753   \n",
       "1              1                                          158283753   \n",
       "2              1                                                      \n",
       "3              1                                          158283753   \n",
       "4              1                                                      \n",
       "..           ...                                                ...   \n",
       "95             5                                1354997580346716164   \n",
       "96             0     437520768 34743251 43166813 21436960 104989762   \n",
       "97            27                                         4529166736   \n",
       "98             0    945002912023023616 1214972829449539584 11339...   \n",
       "99             0            437520768 390455433 135275592 104989762   \n",
       "\n",
       "         hashtag              post_id symbols  \n",
       "0     marswebcam  1379577401626263560      []  \n",
       "1     marswebcam  1379575449290895360      []  \n",
       "2     marswebcam  1379572699794640902      []  \n",
       "3     marswebcam  1379572287725264898      []  \n",
       "4     marswebcam  1379572106430709760      []  \n",
       "..           ...                  ...     ...  \n",
       "95                1377462589634977793      []  \n",
       "96                1377462519929872394      []  \n",
       "97                1377462058334228483      []  \n",
       "98                1377460988006531074      []  \n",
       "99                1377458972597186565      []  \n",
       "\n",
       "[593275 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "productive-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "newstartdf = startdf[['user', 'user_id', 'text', 'favorite_count', 'retweet_count',\n",
    "                   'mentions', 'hashtag', 'post_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "spoken-player",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-c679057830a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewstartdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'favorite_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# df = df.append(newstartdf)\n",
    "# df = df.drop_duplicates(subset='post_id')\n",
    "# df = df.sort_values(by='favorite_count', ascending=False).drop_duplicates(subset='text', keep='first')\n",
    "# df = df.reset_index()\n",
    "# print(len(df))\n",
    "# #171476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hashtag'].value_counts().to_frame().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "tamil-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "startdf.to_csv('beeep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since every time we loop through it starts a new index, there are now multiple entries for each index, we need to fix this\n",
    "# and the easiest way is to just reset the index once it finishes running \n",
    "startdf = startdf.drop_duplicates(subset='post_id')\n",
    "startdf = startdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need these columns anymore\n",
    "startdf = startdf.drop(['index', '', 'symbols'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to add our strings for our hashtags and mentions together we had to make the entire column a string, sinlucding empty cells\n",
    "# here we go through and replace empty cells with nan values so pandas will read them as being empty instead of a string\n",
    "for i in range(len(startdf)):\n",
    "    if startdf.at[i, 'mentions'] == ' ':\n",
    "        startdf.at[i, 'mentions'] = np.nan\n",
    "    else: \n",
    "        pass \n",
    "    if startdf.at[i, 'hashtag'] == ' ':\n",
    "        startdf.at[i, 'hashtag'] = np.nan\n",
    "    else: \n",
    "        pass "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
