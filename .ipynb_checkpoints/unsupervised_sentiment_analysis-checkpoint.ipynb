{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below unsupervised learning sentiment analysis takes in a corpus of 514027 rows of Tweets and YouTube comments and finds word, bigram, and sentence associations. Using the associations of the tokens within the corpus, it vectorizes the distances of the associations. The overall process begins by utilizing cleaning techniques such as lemmatization, removal of NaN values and stop words. Secondly by using the Gensim library's Phrases() and Phraser() to convert the individual words into bigrams and clusters of no more than 5 words (note to self--might need to adjust the minimum number of words in a phrase) and vectorizes their associations.\n",
    "\n",
    "The biggest leap here is that since this is unsupervised learning, none of the rows or words already have a predetermined classification. There is no already defined positive, negative, or neutral words or statement. So labeling and tagging the words by first creating associations between them is the first major step before judging the sentiment value (i.e. positive versus negative versus neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-21.0.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools\n",
      "  Downloading setuptools-54.2.0-py3-none-any.whl (785 kB)\n",
      "\u001b[K     |████████████████████████████████| 785 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: pip, setuptools, wheel\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.1\n",
      "    Uninstalling pip-20.2.1:\n",
      "      Successfully uninstalled pip-20.2.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 49.2.1.post20200802\n",
      "    Uninstalling setuptools-49.2.1.post20200802:\n",
      "      Successfully uninstalled setuptools-49.2.1.post20200802\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "Successfully installed pip-21.0.1 setuptools-54.2.0 wheel-0.36.2\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.0.5-cp36-cp36m-macosx_10_9_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 2.7 MB/s eta 0:00:01    |███████▏                        | 2.7 MB 2.7 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.1\n",
      "  Downloading catalogue-2.0.1-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy) (2.24.0)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp36-cp36m-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.4.0-py3-none-any.whl (36 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp36-cp36m-macosx_10_9_x86_64.whl (32 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Downloading spacy_legacy-3.0.2-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Downloading tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.3-cp36-cp36m-macosx_10_9_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 35.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy) (1.19.1)\n",
      "Requirement already satisfied: setuptools in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy) (54.2.0)\n",
      "Collecting thinc<8.1.0,>=8.0.2\n",
      "  Downloading thinc-8.0.2-cp36-cp36m-macosx_10_9_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 19.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy) (2.11.2)\n",
      "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy) (1.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy) (20.4)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp36-cp36m-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 8.4 MB/s eta 0:00:01     |███▌                            | 634 kB 8.4 MB/s eta 0:00:01     |█████████████████████▊          | 3.9 MB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp36-cp36m-macosx_10_9_x86_64.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.0-cp36-cp36m-macosx_10_9_x86_64.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 27.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from importlib-metadata>=0.20->spacy) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Collecting dataclasses<1.0,>=0.6\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Collecting contextvars<3,>=2.4\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.15-cp36-cp36m-macosx_10_14_x86_64.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 4.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click<7.2.0,>=7.1.1 in /Users/tlipman/.local/lib/python3.6/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Building wheels for collected packages: smart-open, contextvars\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=4b2c85c3a92561a5b0f5bd2a5b9e539b474a9029ff84216944a480776c002bb3\n",
      "  Stored in directory: /Users/tlipman/Library/Caches/pip/wheels/88/2a/d4/f2e9023989d4d4b3574f268657cb6cd23994665a038803f547\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=9ff73195c1106c607d561781ac87fb2b99801799f3129652882c040b6d7a1e44\n",
      "  Stored in directory: /Users/tlipman/Library/Caches/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
      "Successfully built smart-open contextvars\n",
      "Installing collected packages: murmurhash, immutables, dataclasses, cymem, catalogue, wasabi, typing-extensions, typer, srsly, smart-open, pydantic, preshed, contextvars, blis, tqdm, thinc, spacy-legacy, pathy, spacy\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.36.1\n",
      "    Uninstalling tqdm-4.36.1:\n",
      "      Successfully uninstalled tqdm-4.36.1\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.1 contextvars-2.4 cymem-2.0.5 dataclasses-0.8 immutables-0.15 murmurhash-1.0.5 pathy-0.4.0 preshed-3.0.5 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.5 spacy-legacy-3.0.2 srsly-2.4.0 thinc-8.0.2 tqdm-4.59.0 typer-0.3.2 typing-extensions-3.7.4.3 wasabi-0.8.2\n",
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 9.6 MB/s eta 0:00:01     |███████████████████████████████ | 13.3 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (54.2.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.59.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: jinja2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from importlib-metadata>=0.20->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.0)\n",
      "Requirement already satisfied: six in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from thinc<8.1.0,>=8.0.2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from contextvars<3,>=2.4->thinc<8.1.0,>=8.0.2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.15)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/tlipman/.local/lib/python3.6/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.0.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (1.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.0.1-cp36-cp36m-macosx_10_9_x86_64.whl (23.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 34.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: dataclasses in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from gensim) (0.8)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from gensim) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from gensim) (1.5.0)\n",
      "Requirement already satisfied: requests in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', None)\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(514027, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lemm.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>deployment 60 starlink satellite confirmed</td>\n",
       "      <td>97534.0</td>\n",
       "      <td>34743251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9272.0</td>\n",
       "      <td>1.367407e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sn11 almost ready fly</td>\n",
       "      <td>60997.0</td>\n",
       "      <td>44196397.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4389.0</td>\n",
       "      <td>1.371995e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ive continued driving scout spot ill drop mar helicopter area get certified fli</td>\n",
       "      <td>56739.0</td>\n",
       "      <td>1.23278323762312e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5605.0</td>\n",
       "      <td>1.369068e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>honestly hadnt seen eye didnt footage would 100  think cg</td>\n",
       "      <td>40107.0</td>\n",
       "      <td>3167257102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5219.0</td>\n",
       "      <td>1.371988e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>really doe look like something 80 sci fi show credit spacex</td>\n",
       "      <td>36838.0</td>\n",
       "      <td>9.294728238480302e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2216.0</td>\n",
       "      <td>1.367993e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                               text  \\\n",
       "0                                        deployment 60 starlink satellite confirmed   \n",
       "1                                                             sn11 almost ready fly   \n",
       "2   ive continued driving scout spot ill drop mar helicopter area get certified fli   \n",
       "3                         honestly hadnt seen eye didnt footage would 100  think cg   \n",
       "4                       really doe look like something 80 sci fi show credit spacex   \n",
       "\n",
       "   favorite_count                user_id mentions  repost_count       post_id  \n",
       "0         97534.0             34743251.0      NaN        9272.0  1.367407e+18  \n",
       "1         60997.0             44196397.0      NaN        4389.0  1.371995e+18  \n",
       "2         56739.0   1.23278323762312e+18      NaN        5605.0  1.369068e+18  \n",
       "3         40107.0           3167257102.0      NaN        5219.0  1.371988e+18  \n",
       "4         36838.0  9.294728238480302e+17      NaN        2216.0  1.367993e+18  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deployment 60 starlink satellite confirmed</td>\n",
       "      <td>97534.0</td>\n",
       "      <td>34743251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9272.0</td>\n",
       "      <td>1.367407e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sn11 almost ready fly</td>\n",
       "      <td>60997.0</td>\n",
       "      <td>44196397.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4389.0</td>\n",
       "      <td>1.371995e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive continued driving scout spot ill drop mar helicopter area get certified fli</td>\n",
       "      <td>56739.0</td>\n",
       "      <td>1.23278323762312e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5605.0</td>\n",
       "      <td>1.369068e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honestly hadnt seen eye didnt footage would 100  think cg</td>\n",
       "      <td>40107.0</td>\n",
       "      <td>3167257102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5219.0</td>\n",
       "      <td>1.371988e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really doe look like something 80 sci fi show credit spacex</td>\n",
       "      <td>36838.0</td>\n",
       "      <td>9.294728238480302e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2216.0</td>\n",
       "      <td>1.367993e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               text  \\\n",
       "0                                        deployment 60 starlink satellite confirmed   \n",
       "1                                                             sn11 almost ready fly   \n",
       "2   ive continued driving scout spot ill drop mar helicopter area get certified fli   \n",
       "3                         honestly hadnt seen eye didnt footage would 100  think cg   \n",
       "4                       really doe look like something 80 sci fi show credit spacex   \n",
       "\n",
       "   favorite_count                user_id mentions  repost_count       post_id  \n",
       "0         97534.0             34743251.0      NaN        9272.0  1.367407e+18  \n",
       "1         60997.0             44196397.0      NaN        4389.0  1.371995e+18  \n",
       "2         56739.0   1.23278323762312e+18      NaN        5605.0  1.369068e+18  \n",
       "3         40107.0           3167257102.0      NaN        5219.0  1.371988e+18  \n",
       "4         36838.0  9.294728238480302e+17      NaN        2216.0  1.367993e+18  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                  81\n",
       "favorite_count         0\n",
       "user_id                3\n",
       "mentions          181446\n",
       "repost_count           0\n",
       "post_id                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df.drop(['favorite_count', 'user_id', 'mentions', 'repost_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       0\n",
       "post_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments = df_comments.dropna().reset_index(drop=True)\n",
    "df_comments.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deployment 60 starlink satellite confirmed</td>\n",
       "      <td>1.367407e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sn11 almost ready fly</td>\n",
       "      <td>1.371995e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive continued driving scout spot ill drop mar helicopter area get certified fli</td>\n",
       "      <td>1.369068e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honestly hadnt seen eye didnt footage would 100  think cg</td>\n",
       "      <td>1.371988e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really doe look like something 80 sci fi show credit spacex</td>\n",
       "      <td>1.367993e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               text  \\\n",
       "0                                        deployment 60 starlink satellite confirmed   \n",
       "1                                                             sn11 almost ready fly   \n",
       "2   ive continued driving scout spot ill drop mar helicopter area get certified fli   \n",
       "3                         honestly hadnt seen eye didnt footage would 100  think cg   \n",
       "4                       really doe look like something 80 sci fi show credit spacex   \n",
       "\n",
       "        post_id  \n",
       "0  1.367407e+18  \n",
       "1  1.371995e+18  \n",
       "2  1.369068e+18  \n",
       "3  1.371988e+18  \n",
       "4  1.367993e+18  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-alphabetical characters in 'text' column\n",
    "\n",
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df_comments['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 8.75 mins\n"
     ]
    }
   ],
   "source": [
    "# Process texts as a stream, and yield `Doc` objects in order.\n",
    "\n",
    "t = time()\n",
    "\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500924, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deployment starlink satellite confirm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sn ready fly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ve continue drive scout spot ill drop mar helicopter area certify fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honestly nt see eye nt footage think cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doe look like sci fi credit spacex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     clean\n",
       "0                                    deployment starlink satellite confirm\n",
       "1                                                             sn ready fly\n",
       "2    ve continue drive scout spot ill drop mar helicopter area certify fli\n",
       "3                                  honestly nt see eye nt footage think cg\n",
       "4                                       doe look like sci fi credit spacex"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tlipman/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Utilizing Gensim Phrases package to automatically detect common phrases (bigrams)\n",
    "# from a list of sentences. https://radimrehurek.com/gensim/models/phrases.html\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 06:56:31: collecting all words and their counts\n",
      "INFO - 06:56:31: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 06:56:32: PROGRESS: at sentence #10000, processed 100114 words and 87342 word types\n",
      "INFO - 06:56:32: PROGRESS: at sentence #20000, processed 198794 words and 162683 word types\n",
      "INFO - 06:56:32: PROGRESS: at sentence #30000, processed 297712 words and 234295 word types\n",
      "INFO - 06:56:32: PROGRESS: at sentence #40000, processed 395270 words and 301893 word types\n",
      "INFO - 06:56:32: PROGRESS: at sentence #50000, processed 492039 words and 365707 word types\n",
      "INFO - 06:56:32: PROGRESS: at sentence #60000, processed 588500 words and 427226 word types\n",
      "INFO - 06:56:33: PROGRESS: at sentence #70000, processed 683840 words and 486520 word types\n",
      "INFO - 06:56:33: PROGRESS: at sentence #80000, processed 778614 words and 544369 word types\n",
      "INFO - 06:56:33: PROGRESS: at sentence #90000, processed 871368 words and 601094 word types\n",
      "INFO - 06:56:33: PROGRESS: at sentence #100000, processed 963971 words and 656715 word types\n",
      "INFO - 06:56:33: PROGRESS: at sentence #110000, processed 1055932 words and 710347 word types\n",
      "INFO - 06:56:34: PROGRESS: at sentence #120000, processed 1145787 words and 761448 word types\n",
      "INFO - 06:56:34: PROGRESS: at sentence #130000, processed 1233804 words and 809946 word types\n",
      "INFO - 06:56:34: PROGRESS: at sentence #140000, processed 1320930 words and 857300 word types\n",
      "INFO - 06:56:34: PROGRESS: at sentence #150000, processed 1407901 words and 904914 word types\n",
      "INFO - 06:56:34: PROGRESS: at sentence #160000, processed 1494247 words and 953396 word types\n",
      "INFO - 06:56:34: PROGRESS: at sentence #170000, processed 1580180 words and 1001455 word types\n",
      "INFO - 06:56:35: PROGRESS: at sentence #180000, processed 1666651 words and 1049221 word types\n",
      "INFO - 06:56:35: PROGRESS: at sentence #190000, processed 1753861 words and 1095365 word types\n",
      "INFO - 06:56:35: PROGRESS: at sentence #200000, processed 1840973 words and 1140831 word types\n",
      "INFO - 06:56:35: PROGRESS: at sentence #210000, processed 1929337 words and 1187140 word types\n",
      "INFO - 06:56:35: PROGRESS: at sentence #220000, processed 2022876 words and 1232496 word types\n",
      "INFO - 06:56:35: PROGRESS: at sentence #230000, processed 2117724 words and 1275305 word types\n",
      "INFO - 06:56:36: PROGRESS: at sentence #240000, processed 2217516 words and 1314984 word types\n",
      "INFO - 06:56:36: PROGRESS: at sentence #250000, processed 2311978 words and 1353013 word types\n",
      "INFO - 06:56:36: PROGRESS: at sentence #260000, processed 2412904 words and 1389296 word types\n",
      "INFO - 06:56:37: PROGRESS: at sentence #270000, processed 2510409 words and 1428175 word types\n",
      "INFO - 06:56:37: PROGRESS: at sentence #280000, processed 2611381 words and 1468633 word types\n",
      "INFO - 06:56:37: PROGRESS: at sentence #290000, processed 2715933 words and 1509817 word types\n",
      "INFO - 06:56:37: PROGRESS: at sentence #300000, processed 2817663 words and 1547801 word types\n",
      "INFO - 06:56:37: PROGRESS: at sentence #310000, processed 2915474 words and 1588508 word types\n",
      "INFO - 06:56:38: PROGRESS: at sentence #320000, processed 3012327 words and 1633348 word types\n",
      "INFO - 06:56:38: PROGRESS: at sentence #330000, processed 3109904 words and 1671660 word types\n",
      "INFO - 06:56:38: PROGRESS: at sentence #340000, processed 3208825 words and 1711522 word types\n",
      "INFO - 06:56:38: PROGRESS: at sentence #350000, processed 3314596 words and 1754506 word types\n",
      "INFO - 06:56:38: PROGRESS: at sentence #360000, processed 3412319 words and 1793626 word types\n",
      "INFO - 06:56:38: PROGRESS: at sentence #370000, processed 3512462 words and 1832530 word types\n",
      "INFO - 06:56:39: PROGRESS: at sentence #380000, processed 3614138 words and 1868337 word types\n",
      "INFO - 06:56:39: PROGRESS: at sentence #390000, processed 3709086 words and 1909353 word types\n",
      "INFO - 06:56:39: PROGRESS: at sentence #400000, processed 3809764 words and 1950103 word types\n",
      "INFO - 06:56:39: PROGRESS: at sentence #410000, processed 3903895 words and 1990292 word types\n",
      "INFO - 06:56:39: PROGRESS: at sentence #420000, processed 3998432 words and 2031016 word types\n",
      "INFO - 06:56:40: PROGRESS: at sentence #430000, processed 4097164 words and 2075753 word types\n",
      "INFO - 06:56:40: PROGRESS: at sentence #440000, processed 4195227 words and 2114695 word types\n",
      "INFO - 06:56:40: PROGRESS: at sentence #450000, processed 4299809 words and 2149637 word types\n",
      "INFO - 06:56:40: PROGRESS: at sentence #460000, processed 4400418 words and 2184346 word types\n",
      "INFO - 06:56:40: PROGRESS: at sentence #470000, processed 4496443 words and 2223460 word types\n",
      "INFO - 06:56:41: PROGRESS: at sentence #480000, processed 4595097 words and 2266443 word types\n",
      "INFO - 06:56:41: PROGRESS: at sentence #490000, processed 4693712 words and 2313718 word types\n",
      "INFO - 06:56:41: PROGRESS: at sentence #500000, processed 4790923 words and 2357515 word types\n",
      "INFO - 06:56:41: collected 2361650 token types (unigram + bigrams) from a corpus of 4799749 words and 500924 sentences\n",
      "INFO - 06:56:41: merged Phrases<2361650 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 06:56:41: Phrases lifecycle event {'msg': 'built Phrases<2361650 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000> in 9.62s', 'datetime': '2021-04-07T06:56:41.566997', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 13:42:17) \\n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Detect phrases based on collocation counts.\n",
    "phrases = Phrases(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 06:58:47: exporting phrases from Phrases<2361650 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 06:58:53: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<24851 phrases, min_count=5, threshold=10.0> from Phrases<2361650 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000> in 6.10s', 'datetime': '2021-04-07T06:58:53.684451', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 13:42:17) \\n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# The goal of Phraser() is to cut down memory consumption of Phrases(),\n",
    "\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the corpus based upon bigrams detected\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369182"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a word frequency count for each individual word\n",
    "# ensuring that lemmatization, removal of stop words, and bigrams reduced\n",
    "# the total diversity of sentiment to be able to be more accurately measured and understood\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['space', 'mar', 'nasa', 'http_co', 'nt', 'spacex', 'wa', 'm', 'like', 'ha']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The latter approach would be an unsupervised one,\n",
    "and this one is an object of interest in this article. \n",
    "The main idea behind unsupervised learning is that you \n",
    "don’t give any previous assumptions and definitions to \n",
    "the model about the outcome of variables you feed into \n",
    "it — you simply insert the data (of course preprocessed before), \n",
    "and want the model to learn the structure of the data itself. \n",
    "It is extremely useful in cases when you don’t have labeled data, \n",
    "or you are not sure about the structure of the data, \n",
    "and you want to learn more about the nature of process you are analyzing, \n",
    "without making any previous assumptions about its outcome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
